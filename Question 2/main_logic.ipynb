{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_birth = pd.read_csv('./data/2_BirthsAndFertilityRatesAnnual.csv')\n",
    "df_price = pd.read_csv('./data/COEBiddingResultsPrices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "df_price['bids_success'] = df_price['bids_success'].str.replace(',', '').astype(int)\n",
    "df_price['bids_received'] = df_price['bids_received'].str.replace(',', '').astype(int)\n",
    "df_price['bidding_no'] = df_price['bidding_no'].astype(str)\n",
    "\n",
    "df_price['bid_success_rate'] = df_price['bids_success'] / df_price['bids_received']\n",
    "df_price['bid_fulfil_rate'] = df_price['bids_success'] / df_price['quota']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COECategoryPredictor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.feature_names = []\n",
    "        \n",
    "    def load_and_merge_data(self, coe_df, birth_df):\n",
    "\n",
    "        coe_data = coe_df.copy()\n",
    "        coe_data['year'] = coe_data['month'].str[:4].astype(int)\n",
    "        coe_data['month_num'] = coe_data['month'].str[5:7].astype(int)\n",
    "        \n",
    "        birth_data = birth_df.copy()\n",
    "        \n",
    "        key_age_groups = ['25 - 29 Years', '30 - 34 Years', '35 - 39 Years', '40 - 44 Years']\n",
    "        birth_features = {}\n",
    "        \n",
    "        for year in range(2010, 2025):\n",
    "            year_str = str(year)\n",
    "            if year_str in birth_data.columns:\n",
    "                year_data = {}\n",
    "                for idx, row in birth_data.iterrows():\n",
    "                    age_group = row.iloc[0]\n",
    "                    if age_group in key_age_groups:\n",
    "                        clean_age = age_group.replace(' - ', '_').replace(' Years', '').replace(' ', '_')\n",
    "                        year_data[f'birth_rate_{clean_age}'] = row[year_str]\n",
    "                \n",
    "                main_age_births = [year_data.get(f'birth_rate_{age}', 0) \n",
    "                                 for age in ['25_29', '30_34', '35_39']]\n",
    "                year_data['birth_rate_main_age'] = sum([x for x in main_age_births if pd.notnull(x)])\n",
    "                \n",
    "                birth_features[year] = year_data\n",
    "\n",
    "        for year, features in birth_features.items():\n",
    "            for feature_name, value in features.items():\n",
    "                coe_data.loc[coe_data['year'] == year, feature_name] = value\n",
    "\n",
    "        return coe_data\n",
    "    \n",
    "    def create_features(self, df):\n",
    "        \n",
    "        df_feat = df.copy()\n",
    "        df_feat = df_feat.sort_values(['vehicle_class', 'month', 'bidding_no'])\n",
    "        \n",
    "        # 1. demand\n",
    "        df_feat['demand_supply_ratio'] = df_feat['bids_received'] / df_feat['quota']\n",
    "        df_feat['excess_demand'] = df_feat['bids_received'] - df_feat['quota']\n",
    "        df_feat['excess_demand_pct'] = df_feat['excess_demand'] / df_feat['quota']\n",
    "        df_feat['success_rate'] = df_feat['bids_success'] / df_feat['bids_received']\n",
    "        df_feat['unfulfilled_demand'] = df_feat['bids_received'] - df_feat['bids_success']\n",
    "        \n",
    "        # 2. time related\n",
    "        df_feat['quarter'] = ((df_feat['month_num'] - 1) // 3 + 1)\n",
    "        df_feat['is_year_end'] = (df_feat['month_num'] >= 11).astype(int)\n",
    "        df_feat['is_mid_year'] = ((df_feat['month_num'] >= 6) & (df_feat['month_num'] <= 8)).astype(int)\n",
    "        \n",
    "        # seasonal\n",
    "        df_feat['month_sin'] = np.sin(2 * np.pi * df_feat['month_num'] / 12)\n",
    "        df_feat['month_cos'] = np.cos(2 * np.pi * df_feat['month_num'] / 12)\n",
    "        \n",
    "        # 3. historical\n",
    "        for lag in [1, 2, 3, 6]:\n",
    "            df_feat[f'premium_lag{lag}'] = df_feat.groupby('vehicle_class')['premium'].shift(lag)\n",
    "            if lag <= 3:\n",
    "                df_feat[f'quota_lag{lag}'] = df_feat.groupby('vehicle_class')['quota'].shift(lag)\n",
    "                df_feat[f'demand_lag{lag}'] = df_feat.groupby('vehicle_class')['bids_received'].shift(lag)\n",
    "        \n",
    "        # 4. ma\n",
    "        for window in [3, 6, 12]:\n",
    "            df_feat[f'premium_ma{window}'] = df_feat.groupby('vehicle_class')['premium'].rolling(window).mean().reset_index(0, drop=True)\n",
    "            df_feat[f'demand_supply_ratio_ma{window}'] = df_feat.groupby('vehicle_class')['demand_supply_ratio'].rolling(window).mean().reset_index(0, drop=True)\n",
    "            if window <= 6:\n",
    "                df_feat[f'quota_ma{window}'] = df_feat.groupby('vehicle_class')['quota'].rolling(window).mean().reset_index(0, drop=True)\n",
    "        \n",
    "        # 5. change ratio\n",
    "        df_feat['premium_pct_change'] = df_feat.groupby('vehicle_class')['premium'].pct_change()\n",
    "        df_feat['quota_change'] = df_feat.groupby('vehicle_class')['quota'].diff()\n",
    "        df_feat['demand_change'] = df_feat.groupby('vehicle_class')['bids_received'].diff()\n",
    "        \n",
    "        # 6. volatility\n",
    "        df_feat['premium_volatility_3m'] = df_feat.groupby('vehicle_class')['premium'].rolling(3).std().reset_index(0, drop=True)\n",
    "        df_feat['premium_volatility_6m'] = df_feat.groupby('vehicle_class')['premium'].rolling(6).std().reset_index(0, drop=True)\n",
    "        \n",
    "        # 7. relative\n",
    "        df_feat['premium_vs_ma3'] = df_feat['premium'] / df_feat['premium_ma3']\n",
    "        df_feat['premium_vs_ma6'] = df_feat['premium'] / df_feat['premium_ma6']\n",
    "        df_feat['ratio_vs_ma3'] = df_feat['demand_supply_ratio'] / df_feat['demand_supply_ratio_ma3']\n",
    "        \n",
    "        # 8. mean, std, min, max\n",
    "        monthly_stats = df_feat.groupby('month').agg({\n",
    "            'premium': ['mean', 'std', 'min', 'max'],\n",
    "            'demand_supply_ratio': 'mean',\n",
    "            'quota': 'sum'\n",
    "        }).round(2)\n",
    "        \n",
    "        monthly_stats.columns = ['market_avg_premium', 'market_premium_std', 'market_min_premium', \n",
    "                               'market_max_premium', 'market_avg_ratio', 'total_quota']\n",
    "        monthly_stats = monthly_stats.reset_index()\n",
    "        \n",
    "        df_feat = df_feat.merge(monthly_stats, on='month', how='left')\n",
    "        \n",
    "        df_feat['premium_vs_market'] = df_feat['premium'] / df_feat['market_avg_premium']\n",
    "        df_feat['ratio_vs_market'] = df_feat['demand_supply_ratio'] / df_feat['market_avg_ratio']\n",
    "        \n",
    "        # 9. birth\n",
    "        birth_cols = [col for col in df_feat.columns if col.startswith('birth_rate_')]\n",
    "        \n",
    "        for col in birth_cols:\n",
    "            if col in df_feat.columns:\n",
    "                df_feat[f'{col}_change'] = df_feat.groupby('vehicle_class')[col].pct_change()\n",
    "                df_feat[f'{col}_ma3'] = df_feat.groupby('vehicle_class')[col].rolling(3).mean().reset_index(0, drop=True)\n",
    "        \n",
    "        df_feat['vehicle_class_encoded'] = self.label_encoder.fit_transform(df_feat['vehicle_class'])\n",
    "        \n",
    "        # clean data\n",
    "        df_feat = df_feat.replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        return df_feat\n",
    "    \n",
    "    def prepare_modeling_data(self, df):\n",
    "        feature_cols = [\n",
    "            'quota', 'bids_received', 'bids_success', 'demand_supply_ratio', 'excess_demand_pct',\n",
    "            'success_rate', 'unfulfilled_demand', 'vehicle_class_encoded',\n",
    "            'year', 'month_num', 'quarter', 'is_year_end', 'is_mid_year', 'month_sin', 'month_cos',\n",
    "            'premium_lag1', 'premium_lag2', 'premium_lag3', 'quota_lag1', 'demand_lag1',\n",
    "            'premium_ma3', 'premium_ma6', 'demand_supply_ratio_ma3', 'quota_ma3',\n",
    "            'premium_pct_change', 'quota_change', 'demand_change',\n",
    "            'premium_volatility_3m', 'premium_volatility_6m',\n",
    "            'premium_vs_ma3', 'premium_vs_ma6', 'premium_vs_market', 'ratio_vs_market',\n",
    "            'market_avg_premium', 'market_premium_std', 'market_avg_ratio', 'total_quota',\n",
    "            'birth_rate_main_age'\n",
    "        ]\n",
    "        \n",
    "        available_features = [col for col in feature_cols if col in df.columns]\n",
    "        self.feature_names = available_features\n",
    "        \n",
    "        # drop na\n",
    "        df_clean = df[available_features + ['premium', 'vehicle_class', 'month']].dropna()\n",
    "        \n",
    "        print(f\"Num features: {len(available_features)}\")\n",
    "        return df_clean\n",
    "    \n",
    "    def train_models(self, df):\n",
    "        results = {}\n",
    "        \n",
    "        for category in df['vehicle_class'].unique():\n",
    "            print(f\"\\train {category} XGBoost...\")\n",
    "            \n",
    "            cat_data = df[df['vehicle_class'] == category].copy()\n",
    "            cat_data = cat_data.sort_values('month')\n",
    "            \n",
    "            if len(cat_data) < 10:\n",
    "                print(f\"  {category} not enough records\")\n",
    "                continue\n",
    "            \n",
    "            X = cat_data[self.feature_names]\n",
    "            y = cat_data['premium']\n",
    "            \n",
    "            split_point = int(len(cat_data) * 0.8)\n",
    "            X_train, X_test = X[:split_point], X[split_point:]\n",
    "            y_train, y_test = y[:split_point], y[split_point:]\n",
    "            \n",
    "            xgb_params = {\n",
    "                'objective': 'reg:squarederror',\n",
    "                'n_estimators': 200,\n",
    "                'max_depth': 6,\n",
    "                'learning_rate': 0.1,\n",
    "                'subsample': 0.8,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'random_state': 42,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            \n",
    "            models = {\n",
    "                'XGBoost_Default': xgb.XGBRegressor(**xgb_params),\n",
    "                'XGBoost_DeepTree': xgb.XGBRegressor(**{**xgb_params, 'max_depth': 8, 'n_estimators': 150}),\n",
    "                'XGBoost_HighLR': xgb.XGBRegressor(**{**xgb_params, 'learning_rate': 0.15, 'n_estimators': 150})\n",
    "            }\n",
    "            \n",
    "            cat_results = {}\n",
    "            \n",
    "            for model_name, model in models.items():\n",
    "                print(f\"  train {model_name}...\")\n",
    "                \n",
    "                model.fit(\n",
    "                    X_train, y_train,\n",
    "                    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "                    eval_metric=['mae', 'mape'],\n",
    "                    early_stopping_rounds=20,\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                y_pred_train = model.predict(X_train)\n",
    "                y_pred_test = model.predict(X_test)\n",
    "\n",
    "                train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "                test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "                train_mape = mean_absolute_percentage_error(y_train, y_pred_train)\n",
    "                test_mape = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "                train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "                test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "                test_r2 = r2_score(y_test, y_pred_test)\n",
    "                \n",
    "                best_iteration = getattr(model, 'best_iteration', model.n_estimators)\n",
    "                \n",
    "                cat_results[model_name] = {\n",
    "                    'model': model,\n",
    "                    'train_mae': train_mae,\n",
    "                    'test_mae': test_mae,\n",
    "                    'train_mape': train_mape,\n",
    "                    'test_mape': test_mape,\n",
    "                    'train_rmse': train_rmse,\n",
    "                    'test_rmse': test_rmse,\n",
    "                    'test_r2': test_r2,\n",
    "                    'best_iteration': best_iteration,\n",
    "                    'y_test': y_test,\n",
    "                    'y_pred': y_pred_test\n",
    "                }\n",
    "                \n",
    "                print(f\"    MAE=${test_mae:,.0f}, MAPE={test_mape:,.2f}, RMSE=${test_rmse:,.0f}, R²={test_r2:.3f}, Best iteration:{best_iteration}\")\n",
    "\n",
    "            best_model_name = min(cat_results.keys(), key=lambda x: cat_results[x]['test_mape'])\n",
    "            best_result = cat_results[best_model_name]\n",
    "            \n",
    "            self.models[category] = best_result['model']\n",
    "            \n",
    "            results[category] = {\n",
    "                'best_model': best_model_name,\n",
    "                'all_results': cat_results,\n",
    "                'sample_count': len(cat_data),\n",
    "                'feature_importance': self._get_xgb_feature_importance(best_result['model'])\n",
    "            }\n",
    "            \n",
    "            print(f\"Best model: {best_model_name} (MAPE: {best_result['test_mape']:,.2f})\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _get_xgb_feature_importance(self, model):\n",
    "\n",
    "        importance_dict = model.get_booster().get_score(importance_type='weight')\n",
    "        importance_df = pd.DataFrame([\n",
    "            {'feature': k, 'importance': v} \n",
    "            for k, v in importance_dict.items()\n",
    "        ]).sort_values('importance', ascending=False)\n",
    "        \n",
    "        return importance_df\n",
    "    \n",
    "    def predict_category(self, category, features):\n",
    "        if category not in self.models:\n",
    "            raise ValueError(f\"cannot find {category}\")\n",
    "        \n",
    "        model = self.models[category]\n",
    "        \n",
    "        prediction = model.predict(features)\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def get_feature_importance(self, category):\n",
    "\n",
    "        if category not in self.models:\n",
    "            return None\n",
    "        \n",
    "        model = self.models[category]\n",
    "        \n",
    "        importance_types = ['weight', 'gain', 'cover']\n",
    "        importance_results = {}\n",
    "        \n",
    "        for imp_type in importance_types:\n",
    "            try:\n",
    "                importance_dict = model.get_booster().get_score(importance_type=imp_type)\n",
    "                importance_df = pd.DataFrame([\n",
    "                    {'feature': k, 'importance': v} \n",
    "                    for k, v in importance_dict.items()\n",
    "                ]).sort_values('importance', ascending=False)\n",
    "                importance_results[imp_type] = importance_df\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return importance_results.get('weight', None)\n",
    "    \n",
    "    def plot_feature_importance(self, category, top_n=15, importance_type='weight'):\n",
    "        if category not in self.models:\n",
    "            print(f\"Cannot find {category}\")\n",
    "            return\n",
    "        \n",
    "        model = self.models[category]\n",
    "        \n",
    "        try:\n",
    "            importance_dict = model.get_booster().get_score(importance_type=importance_type)\n",
    "            importance_df = pd.DataFrame([\n",
    "                {'feature': k, 'importance': v} \n",
    "                for k, v in importance_dict.items()\n",
    "            ]).sort_values('importance', ascending=False).head(top_n)\n",
    "            \n",
    "            plt.figure(figsize=(10, 8))\n",
    "            plt.barh(range(len(importance_df)), importance_df['importance'])\n",
    "            plt.yticks(range(len(importance_df)), importance_df['feature'])\n",
    "            plt.xlabel(f'Feature Importance ({importance_type})')\n",
    "            plt.title(f'{category} - XGBoost Feature Importance')\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"fail: {e}\")\n",
    "    \n",
    "    def predict_with_confidence(self, category, features, n_estimators_range=(50, 200)):\n",
    "        if category not in self.models:\n",
    "            raise ValueError(f\"Cannot find {category} \")\n",
    "        \n",
    "        model = self.models[category]\n",
    "        predictions = []\n",
    "\n",
    "        for n_trees in range(n_estimators_range[0], n_estimators_range[1], 25):\n",
    "            temp_model = model\n",
    "            temp_model.n_estimators = min(n_trees, model.n_estimators)\n",
    "            pred = temp_model.predict(features.reshape(1, -1))[0]\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        mean_pred = np.mean(predictions)\n",
    "        std_pred = np.std(predictions)\n",
    "        \n",
    "        return {\n",
    "            'prediction': mean_pred,\n",
    "            'confidence_interval': (mean_pred - 1.96*std_pred, mean_pred + 1.96*std_pred),\n",
    "            'std_dev': std_pred\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 38\n"
     ]
    }
   ],
   "source": [
    "predictor = COECategoryPredictor()\n",
    "merged_data = predictor.load_and_merge_data(df_price, df_birth)\n",
    "featured_data = predictor.create_features(merged_data)\n",
    "model_data = predictor.prepare_modeling_data(featured_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\train Category A XGBoost...\n",
      "  train XGBoost_Default...\n",
      "    MAE=$5,304, MAPE=0.06, RMSE=$6,813, R²=0.606, Best iteration:103\n",
      "  train XGBoost_DeepTree...\n",
      "    MAE=$5,360, MAPE=0.06, RMSE=$6,895, R²=0.597, Best iteration:101\n",
      "  train XGBoost_HighLR...\n",
      "    MAE=$5,712, MAPE=0.06, RMSE=$7,711, R²=0.496, Best iteration:89\n",
      "Best model: XGBoost_Default (MAPE: 0.06)\n",
      "\train Category B XGBoost...\n",
      "  train XGBoost_Default...\n",
      "    MAE=$18,431, MAPE=0.16, RMSE=$21,775, R²=-1.856, Best iteration:176\n",
      "  train XGBoost_DeepTree...\n",
      "    MAE=$18,004, MAPE=0.16, RMSE=$21,300, R²=-1.733, Best iteration:149\n",
      "  train XGBoost_HighLR...\n",
      "    MAE=$18,400, MAPE=0.16, RMSE=$21,777, R²=-1.856, Best iteration:135\n",
      "Best model: XGBoost_DeepTree (MAPE: 0.16)\n",
      "\train Category C XGBoost...\n",
      "  train XGBoost_Default...\n",
      "    MAE=$5,106, MAPE=0.07, RMSE=$6,857, R²=0.613, Best iteration:156\n",
      "  train XGBoost_DeepTree...\n",
      "    MAE=$5,110, MAPE=0.07, RMSE=$6,840, R²=0.615, Best iteration:149\n",
      "  train XGBoost_HighLR...\n",
      "    MAE=$5,143, MAPE=0.07, RMSE=$6,883, R²=0.610, Best iteration:102\n",
      "Best model: XGBoost_Default (MAPE: 0.07)\n",
      "\train Category D XGBoost...\n",
      "  train XGBoost_Default...\n",
      "    MAE=$1,159, MAPE=0.11, RMSE=$1,526, R²=-0.343, Best iteration:163\n",
      "  train XGBoost_DeepTree...\n",
      "    MAE=$1,155, MAPE=0.11, RMSE=$1,522, R²=-0.337, Best iteration:149\n",
      "  train XGBoost_HighLR...\n",
      "    MAE=$1,112, MAPE=0.11, RMSE=$1,476, R²=-0.257, Best iteration:89\n",
      "Best model: XGBoost_HighLR (MAPE: 0.11)\n",
      "\train Category E XGBoost...\n",
      "  train XGBoost_Default...\n",
      "    MAE=$18,184, MAPE=0.15, RMSE=$22,297, R²=-1.665, Best iteration:149\n",
      "  train XGBoost_DeepTree...\n",
      "    MAE=$18,187, MAPE=0.15, RMSE=$22,400, R²=-1.689, Best iteration:149\n",
      "  train XGBoost_HighLR...\n",
      "    MAE=$20,035, MAPE=0.17, RMSE=$23,790, R²=-2.033, Best iteration:88\n",
      "Best model: XGBoost_DeepTree (MAPE: 0.15)\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "results = predictor.train_models(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category A:\n",
      "  Sample count: 349\n",
      "  best model: XGBoost_Default\n",
      "  top 5 features:\n",
      "    quota: 228.0\n",
      "    premium_vs_market: 147.0\n",
      "    premium_vs_ma3: 127.0\n",
      "    premium_ma3: 124.0\n",
      "    market_avg_premium: 120.0\n",
      "  Metrics: MAE=$5,304, MAPE=0.06, R²=0.606\n",
      "  best interations: 103\n",
      "\n",
      "Category B:\n",
      "  Sample count: 349\n",
      "  best model: XGBoost_DeepTree\n",
      "  top 5 features:\n",
      "    quota: 656.0\n",
      "    bids_received: 358.0\n",
      "    premium_vs_market: 311.0\n",
      "    demand_supply_ratio: 251.0\n",
      "    premium_pct_change: 220.0\n",
      "  Metrics: MAE=$18,004, MAPE=0.16, R²=-1.733\n",
      "  best interations: 149\n",
      "\n",
      "Category C:\n",
      "  Sample count: 349\n",
      "  best model: XGBoost_Default\n",
      "  top 5 features:\n",
      "    quota: 353.0\n",
      "    bids_received: 221.0\n",
      "    premium_ma3: 201.0\n",
      "    premium_pct_change: 199.0\n",
      "    premium_lag1: 196.0\n",
      "  Metrics: MAE=$5,106, MAPE=0.07, R²=0.613\n",
      "  best interations: 156\n",
      "\n",
      "Category D:\n",
      "  Sample count: 349\n",
      "  best model: XGBoost_HighLR\n",
      "  top 5 features:\n",
      "    quota: 185.0\n",
      "    premium_ma3: 147.0\n",
      "    bids_received: 127.0\n",
      "    premium_vs_ma6: 110.0\n",
      "    premium_vs_ma3: 106.0\n",
      "  Metrics: MAE=$1,112, MAPE=0.11, R²=-0.257\n",
      "  best interations: 89\n",
      "\n",
      "Category E:\n",
      "  Sample count: 349\n",
      "  best model: XGBoost_DeepTree\n",
      "  top 5 features:\n",
      "    quota: 598.0\n",
      "    premium_vs_market: 340.0\n",
      "    bids_received: 325.0\n",
      "    demand_supply_ratio: 251.0\n",
      "    premium_pct_change: 217.0\n",
      "  Metrics: MAE=$18,187, MAPE=0.15, R²=-1.689\n",
      "  best interations: 149\n"
     ]
    }
   ],
   "source": [
    "# output\n",
    "for category, result in results.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    print(f\"  Sample count: {result['sample_count']}\")\n",
    "    print(f\"  best model: {result['best_model']}\")\n",
    "    \n",
    "    if 'feature_importance' in result and result['feature_importance'] is not None:\n",
    "        importance = result['feature_importance']\n",
    "        print(f\"  top 5 features:\")\n",
    "        for _, row in importance.head(5).iterrows():\n",
    "            print(f\"    {row['feature']}: {row['importance']:.1f}\")\n",
    "\n",
    "    best_model_results = result['all_results'][result['best_model']]\n",
    "    print(f\"  Metrics: MAE=${best_model_results['test_mae']:,.0f}, MAPE={best_model_results['test_mape']:,.2f}, R²={best_model_results['test_r2']:.3f}\")\n",
    "    print(f\"  best interations: {best_model_results['best_iteration']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vehicle_class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Category A</th>\n",
       "      <td>368.0</td>\n",
       "      <td>58380.500000</td>\n",
       "      <td>22291.714224</td>\n",
       "      <td>18502.0</td>\n",
       "      <td>40687.75</td>\n",
       "      <td>55299.5</td>\n",
       "      <td>74989.50</td>\n",
       "      <td>106000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category B</th>\n",
       "      <td>368.0</td>\n",
       "      <td>69803.095109</td>\n",
       "      <td>27903.787629</td>\n",
       "      <td>19190.0</td>\n",
       "      <td>47000.75</td>\n",
       "      <td>65511.0</td>\n",
       "      <td>90625.75</td>\n",
       "      <td>150001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category C</th>\n",
       "      <td>368.0</td>\n",
       "      <td>48048.399457</td>\n",
       "      <td>16788.484831</td>\n",
       "      <td>19001.0</td>\n",
       "      <td>32889.75</td>\n",
       "      <td>46945.5</td>\n",
       "      <td>58665.00</td>\n",
       "      <td>91101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category D</th>\n",
       "      <td>368.0</td>\n",
       "      <td>5789.940217</td>\n",
       "      <td>3260.129143</td>\n",
       "      <td>852.0</td>\n",
       "      <td>2457.50</td>\n",
       "      <td>6101.0</td>\n",
       "      <td>8674.00</td>\n",
       "      <td>13189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category E</th>\n",
       "      <td>368.0</td>\n",
       "      <td>71009.817935</td>\n",
       "      <td>28334.653375</td>\n",
       "      <td>19889.0</td>\n",
       "      <td>48009.50</td>\n",
       "      <td>65545.0</td>\n",
       "      <td>92391.75</td>\n",
       "      <td>158004.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count          mean           std      min       25%      50%  \\\n",
       "vehicle_class                                                                  \n",
       "Category A     368.0  58380.500000  22291.714224  18502.0  40687.75  55299.5   \n",
       "Category B     368.0  69803.095109  27903.787629  19190.0  47000.75  65511.0   \n",
       "Category C     368.0  48048.399457  16788.484831  19001.0  32889.75  46945.5   \n",
       "Category D     368.0   5789.940217   3260.129143    852.0   2457.50   6101.0   \n",
       "Category E     368.0  71009.817935  28334.653375  19889.0  48009.50  65545.0   \n",
       "\n",
       "                    75%       max  \n",
       "vehicle_class                      \n",
       "Category A     74989.50  106000.0  \n",
       "Category B     90625.75  150001.0  \n",
       "Category C     58665.00   91101.0  \n",
       "Category D      8674.00   13189.0  \n",
       "Category E     92391.75  158004.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price.groupby('vehicle_class').premium.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Category A feature importance:\n",
      "Top 10 features:\n",
      "   1. quota: 228.0\n",
      "   2. premium_vs_market: 147.0\n",
      "   3. premium_vs_ma3: 127.0\n",
      "   4. premium_ma3: 124.0\n",
      "   5. market_avg_premium: 120.0\n",
      "   6. premium_pct_change: 113.0\n",
      "   7. premium_lag1: 113.0\n",
      "   8. premium_vs_ma6: 108.0\n",
      "   9. bids_received: 107.0\n",
      "  10. premium_volatility_3m: 100.0\n",
      "\n",
      " Category B feature importance:\n",
      "Top 10 features:\n",
      "   1. quota: 656.0\n",
      "   2. bids_received: 358.0\n",
      "   3. premium_vs_market: 311.0\n",
      "   4. demand_supply_ratio: 251.0\n",
      "   5. premium_pct_change: 220.0\n",
      "   6. premium_lag1: 213.0\n",
      "   7. demand_change: 196.0\n",
      "   8. quota_change: 196.0\n",
      "   9. premium_volatility_3m: 192.0\n",
      "  10. premium_lag3: 173.0\n",
      "\n",
      " Category C feature importance:\n",
      "Top 10 features:\n",
      "   1. quota: 353.0\n",
      "   2. bids_received: 221.0\n",
      "   3. premium_ma3: 201.0\n",
      "   4. premium_pct_change: 199.0\n",
      "   5. premium_lag1: 196.0\n",
      "   6. demand_supply_ratio: 189.0\n",
      "   7. premium_vs_ma3: 179.0\n",
      "   8. premium_vs_ma6: 154.0\n",
      "   9. premium_volatility_3m: 140.0\n",
      "  10. demand_supply_ratio_ma3: 137.0\n",
      "\n",
      " Category D feature importance:\n",
      "Top 10 features:\n",
      "   1. quota: 185.0\n",
      "   2. premium_ma3: 147.0\n",
      "   3. bids_received: 127.0\n",
      "   4. premium_vs_ma6: 110.0\n",
      "   5. premium_vs_ma3: 106.0\n",
      "   6. demand_supply_ratio: 104.0\n",
      "   7. premium_lag1: 81.0\n",
      "   8. premium_pct_change: 77.0\n",
      "   9. premium_volatility_3m: 77.0\n",
      "  10. quota_change: 71.0\n",
      "\n",
      " Category E feature importance:\n",
      "Top 10 features:\n",
      "   1. quota: 598.0\n",
      "   2. premium_vs_market: 340.0\n",
      "   3. bids_received: 325.0\n",
      "   4. demand_supply_ratio: 251.0\n",
      "   5. premium_pct_change: 217.0\n",
      "   6. premium_vs_ma3: 176.0\n",
      "   7. demand_supply_ratio_ma3: 174.0\n",
      "   8. premium_vs_ma6: 167.0\n",
      "   9. premium_lag1: 159.0\n",
      "  10. quota_change: 158.0\n"
     ]
    }
   ],
   "source": [
    "# feature top 10\n",
    "\n",
    "for i in range(5):\n",
    "    first_category = list(predictor.models.keys())[i]\n",
    "    print(f\"\\n {first_category} feature importance:\")\n",
    "    importance = predictor.get_feature_importance(first_category)\n",
    "    if importance is not None:\n",
    "        print(\"Top 10 features:\")\n",
    "        for i, (_, row) in enumerate(importance.head(10).iterrows(), 1):\n",
    "            print(f\"  {i:2d}. {row['feature']}: {row['importance']:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quota suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. change quota values: Current ± 5%, ±10%, ±15%, ±20%\n",
    "# 3. test in XGBoost model → Get predicted prices\n",
    "# 4. Map quota change % to price change %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para\n",
    "ls_quota_features = ['quota',\n",
    "#  'quota_lag1',\n",
    "#  'quota_lag2',\n",
    "#  'quota_lag3',\n",
    "#  'quota_ma3',\n",
    "#  'quota_ma6',\n",
    "#  'quota_change',\n",
    "#  'total_quota'\n",
    " ]\n",
    "\n",
    "ls_ratio = [0.95, 1.05, 0.9, 1.1, 0.85, 1.15, 0.8, 1.2]\n",
    "# ls_ratio = [0.1, .05]\n",
    "ls_categories = list(predictor.models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category A\n",
      "       0.95   1.05   0.90   1.10   0.85   1.15   0.80   1.20\n",
      "mean  2.12%  2.17%  2.20%  2.40%  2.22%  2.68%  2.25%  2.82%\n",
      "std   4.91%  4.90%  4.91%  4.88%  4.90%  4.88%  4.90%  4.90%\n",
      "Category B\n",
      "       0.95   1.05   0.90   1.10   0.85   1.15   0.80   1.20\n",
      "mean  4.44%  4.46%  4.51%  4.53%  4.58%  4.57%  4.63%  4.60%\n",
      "std   8.67%  8.66%  8.63%  8.64%  8.61%  8.61%  8.57%  8.60%\n",
      "Category C\n",
      "       0.95   1.05   0.90   1.10   0.85   1.15   0.80   1.20\n",
      "mean  1.72%  1.67%  1.79%  1.74%  1.83%  1.77%  1.94%  1.81%\n",
      "std   3.63%  3.60%  3.62%  3.56%  3.61%  3.51%  3.67%  3.57%\n",
      "Category D\n",
      "       0.95   1.05   0.90   1.10   0.85   1.15   0.80   1.20\n",
      "mean  3.08%  3.08%  3.27%  3.28%  3.42%  3.44%  3.53%  3.56%\n",
      "std   7.70%  7.77%  7.66%  7.72%  7.65%  7.67%  7.67%  7.64%\n",
      "Category E\n",
      "       0.95   1.05   0.90   1.10   0.85   1.15   0.80   1.20\n",
      "mean  4.52%  4.52%  4.64%  4.74%  4.71%  4.91%  4.79%  5.05%\n",
      "std   9.02%  8.92%  8.98%  8.82%  8.95%  8.72%  8.92%  8.64%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for category in ls_categories: \n",
    "    df_output = pd.DataFrame()\n",
    "    for ratio in ls_ratio: \n",
    "        # update ratio\n",
    "        df_tmp = merged_data.copy()\n",
    "        df_tmp[ls_quota_features] = df_tmp[ls_quota_features] * ratio\n",
    "        new_featured_data = predictor.create_features(df_tmp)\n",
    "\n",
    "        new_featured_data = new_featured_data[new_featured_data['vehicle_class'] == category]\n",
    "        y_true = new_featured_data['premium']\n",
    "        \n",
    "        predicted_price = predictor.predict_category(category, new_featured_data[predictor.feature_names])\n",
    "        \n",
    "        df_tmp = ((predicted_price - y_true).abs()/y_true).describe()[['mean', 'std']]\n",
    "        df_tmp = df_tmp.to_frame()\n",
    "        df_tmp = df_tmp.applymap(lambda x: f\"{x:.2%}\" if isinstance(x, (int, float)) else x)\n",
    "        df_tmp.columns = [ratio]\n",
    "\n",
    "        df_output = pd.concat([df_output, df_tmp], axis=1)\n",
    "\n",
    "    print(category)\n",
    "    print(df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
